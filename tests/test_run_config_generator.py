# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from model_analyzer.config.generate.run_config_generator import RunConfigGenerator
from model_analyzer.config.input.config_command_profile \
     import ConfigCommandProfile
from model_analyzer.cli.cli import CLI
from .common import test_result_collector as trc
from .common.test_utils import convert_to_bytes
from .mocks.mock_config import MockConfig
from .mocks.mock_model_config import MockModelConfig
from .mocks.mock_os import MockOSMethods
from unittest.mock import MagicMock

from model_analyzer.config.generate.generator_utils import GeneratorUtils as utils

from model_analyzer.config.input.config_defaults import \
    DEFAULT_BATCH_SIZES, DEFAULT_TRITON_LAUNCH_MODE, \
    DEFAULT_CLIENT_PROTOCOL, DEFAULT_TRITON_INSTALL_PATH, DEFAULT_OUTPUT_MODEL_REPOSITORY, \
    DEFAULT_TRITON_INSTALL_PATH, DEFAULT_OUTPUT_MODEL_REPOSITORY, \
    DEFAULT_TRITON_HTTP_ENDPOINT, DEFAULT_TRITON_GRPC_ENDPOINT, DEFAULT_MEASUREMENT_MODE, \
    DEFAULT_RUN_CONFIG_MAX_CONCURRENCY, DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT


class TestRunConfigGenerator(trc.TestResultCollector):

    def test_default_config_single_model(self):
        """
        Test Default Single Model:  
            - No CLI options specified
        
       
        log2(DEFAULT_RUN_CONFIG_MAX_CONCURRENCY)+1 PA configs x
        DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT+1 Model configs
        will be generated by the auto-search
        """

        # yapf: disable
        yaml_content = convert_to_bytes("""
            profile_models:
                - my-model
            """)
        # yapf: enable

        expected_pa_configs = len(
            utils.generate_log2_list(DEFAULT_RUN_CONFIG_MAX_CONCURRENCY))
        expected_model_configs = DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT + 1
        expected_num_of_configs = expected_pa_configs * expected_model_configs

        self._run_and_test_run_config_generator(
            yaml_content, expected_config_count=expected_num_of_configs)

    def test_default_config_two_models(self):
        """
        Test Default Two Models:
            - No CLI options specified

        log2(DEFAULT_RUN_CONFIG_MAX_CONCURRENCY)+1 PA configs x
        DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT+1 Model configs
        will be generated by the auto-search
        """

        # yapf: disable
        yaml_content = convert_to_bytes("""
            profile_models:
                - my-model0
                - my-model1
            """)
        # yapf: enable

        expected_pa_configs = len(
            utils.generate_log2_list(DEFAULT_RUN_CONFIG_MAX_CONCURRENCY))
        expected_model_configs = DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT + 1
        expected_num_of_configs = expected_pa_configs * expected_model_configs**2
        self._run_and_test_run_config_generator(
            yaml_content, expected_config_count=expected_num_of_configs)

    def test_default_config_four_models(self):
        """
        Test Default Four Models:
            - No CLI options specified

        log2(DEFAULT_RUN_CONFIG_MAX_CONCURRENCY)+1 PA configs x
        DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT+1 Model configs
        will be generated by the auto-search
        """

        # yapf: disable
        yaml_content = convert_to_bytes("""
            profile_models:
                - my-model0
                - my-model1
                - my-model2
                - my-model3
            """)
        # yapf: enable

        expected_pa_configs = len(
            utils.generate_log2_list(DEFAULT_RUN_CONFIG_MAX_CONCURRENCY))
        expected_model_configs = DEFAULT_RUN_CONFIG_MAX_INSTANCE_COUNT + 1
        expected_num_of_configs = expected_pa_configs * expected_model_configs**4

        self._run_and_test_run_config_generator(
            yaml_content, expected_config_count=expected_num_of_configs)

    def _run_and_test_run_config_generator(self, yaml_content,
                                           expected_config_count):
        args = [
            'model-analyzer', 'profile', '--model-repository', 'cli_repository',
            '-f', 'path-to-config-file'
        ]

        protobuf = """
            max_batch_size: 8
            instance_group [
            {
                kind: KIND_CPU
                count: 1
            }
            ]
            """

        self.mock_model_config = MockModelConfig(protobuf)
        self.mock_model_config.start()
        config = self._evaluate_config(args, yaml_content)

        rcg = RunConfigGenerator(config, config.profile_models, MagicMock())

        run_configs = []
        rcg_config_generator = rcg.next_config()
        while not rcg.is_done():
            run_configs.append(next(rcg_config_generator))

        self.assertEqual(expected_config_count, len(set(run_configs)))

        # Checks that each RunConfig contains the expected number of model_configs
        model_configs = [
            run_config.model_configs() for run_config in run_configs
        ]

        (self.assertEqual(len(config.profile_models),
                          len(set(model_configs[c]))) for c in model_configs)

        self.mock_model_config.stop()

    def _evaluate_config(self, args, yaml_content):
        mock_config = MockConfig(args, yaml_content)
        mock_config.start()
        config = ConfigCommandProfile()
        cli = CLI()
        cli.add_subcommand(
            cmd='profile',
            help=
            'Run model inference profiling based on specified CLI or config options.',
            config=config)
        cli.parse()
        mock_config.stop()
        return config

    def setUp(self):
        # Mock path validation
        self.mock_os = MockOSMethods(
            mock_paths=['model_analyzer.config.input.config_utils'])
        self.mock_os.start()

    def tearDown(self):
        self.mock_os.stop()
