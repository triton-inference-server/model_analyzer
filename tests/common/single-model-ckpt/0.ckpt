{"ResultManager.results": {"_results": {"add_sub": {"add_sub_config_default": [{"_triton_env": {}, "_model_run_configs": [{"_model_name": "add_sub", "_model_config": {"name": "add_sub_config_default", "platform": "pytorch_libtorch", "maxBatchSize": 8, "input": [{"name": "INPUT__0", "dataType": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "dataType": "TYPE_FP32", "dims": ["16"], "labelFilename": "output0_labels.txt"}, {"name": "OUTPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "instanceGroup": [{"kind": "KIND_GPU"}], "cpu_only": false}, "_perf_config": {"_args": {"service-kind": null, "model-signature-name": null, "async": null, "sync": null, "measurement-interval": null, "concurrency-range": 1, "request-rate-range": null, "request-distribution": null, "request-intervals": null, "binary-search": null, "num-of-sequences": null, "latency-threshold": null, "max-threads": null, "stability-percentage": null, "max-trials": null, "percentile": null, "input-data": null, "shared-memory": null, "output-shared-memory-size": null, "shape": null, "sequence-length": null, "sequence-id-range": null, "string-length": null, "string-data": null, "measurement-mode": "count_windows", "measurement-request-count": null, "streaming": null, "grpc-compression-algorithm": null, "triton-server-directory": null, "model-repository": null, "ssl-grpc-use-ssl": null, "ssl-grpc-root-certifications-file": null, "ssl-grpc-private-key-file": null, "ssl-grpc-certificate-chain-file": null, "ssl-https-verify-peer": null, "ssl-https-verify-host": null, "ssl-https-ca-certificates-file": null, "ssl-https-client-certificate-type": null, "ssl-https-client-certificate-file": null, "ssl-https-private-key-type": null, "ssl-https-private-key-file": null, "collect-metrics": "True", "metrics-url": "http://localhost:8002/metrics", "metrics-interval": 1000.0}, "_options": {"-m": "add_sub_config_default", "-x": null, "-b": 1, "-u": "localhost:8001", "-i": "grpc", "-f": "add_sub_config_default-results.csv", "-H": null}, "_verbose": {"-v": null, "-v -v": null, "--verbose-csv": "--verbose-csv"}, "_input_to_options": {"model-name": "-m", "model-version": "-x", "batch-size": "-b", "url": "-u", "protocol": "-i", "latency-report-file": "-f", "http-header": "-H"}, "_input_to_verbose": {"verbose": "-v", "extra-verbose": "-v -v", "verbose-csv": "--verbose-csv"}, "_additive_args": {"input-data": null, "shape": null}}, "_ensemble_subconfigs": []}]}, {"-m add_sub_config_default -b 1 -i grpc -f add_sub_config_default-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_default", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 3.0, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.8185, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 3.0, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.8185, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 3.0, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 55.8185, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_default", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.38, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.437, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.46, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.511, "_timestamp": 0}], ["perf_throughput", {"_value": 2626.05, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.367, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.017, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.066, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.031, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.042, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.38, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.437, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.46, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.511, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 2626.05, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.367, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.017, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.066, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.031, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.042, "_timestamp": 0}]}}]}, "-m add_sub_config_default -b 1 -i grpc -f add_sub_config_default-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_default", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 7.66667, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.0633, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 7.66667, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.0633, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 7.66667, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.0633, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_default", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.307, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.337, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.395, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.54, "_timestamp": 0}], ["perf_throughput", {"_value": 6494.65, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.295, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.037, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.033, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.023, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.307, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.337, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.395, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.54, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 6494.65, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.295, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.037, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.033, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.023, "_timestamp": 0}]}}]}, "-m add_sub_config_default -b 2 -i grpc -f add_sub_config_default-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_default", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.9175, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.9175, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.25, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 55.9175, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_default", "_model_specific_pa_params": {"batch-size": 2, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.394, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.471, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.535, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.637, "_timestamp": 0}], ["perf_throughput", {"_value": 5066.42, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.38, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.018, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.073, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.033, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.043, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.394, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.471, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.535, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.637, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 5066.42, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.38, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.018, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.073, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.033, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.043, "_timestamp": 0}]}}]}, "-m add_sub_config_default -b 2 -i grpc -f add_sub_config_default-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_default", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 5.0, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.9815, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 5.0, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.9815, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 5.0, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 55.9815, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_default", "_model_specific_pa_params": {"batch-size": 2, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.314, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.354, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.408, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.577, "_timestamp": 0}], ["perf_throughput", {"_value": 12693.7, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.301, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.031, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.034, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.022, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.314, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.354, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.408, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.577, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 12693.7, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.301, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.031, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.034, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.022, "_timestamp": 0}]}}]}}], "add_sub_config_0": [{"_triton_env": {}, "_model_run_configs": [{"_model_name": "add_sub", "_model_config": {"name": "add_sub_config_0", "platform": "pytorch_libtorch", "maxBatchSize": 1, "input": [{"name": "INPUT__0", "dataType": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "dataType": "TYPE_FP32", "dims": ["16"], "labelFilename": "output0_labels.txt"}, {"name": "OUTPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "instanceGroup": [{"count": 1, "kind": "KIND_GPU"}], "dynamicBatching": {}, "cpu_only": false}, "_perf_config": {"_args": {"service-kind": null, "model-signature-name": null, "async": null, "sync": null, "measurement-interval": null, "concurrency-range": 1, "request-rate-range": null, "request-distribution": null, "request-intervals": null, "binary-search": null, "num-of-sequences": null, "latency-threshold": null, "max-threads": null, "stability-percentage": null, "max-trials": null, "percentile": null, "input-data": null, "shared-memory": null, "output-shared-memory-size": null, "shape": null, "sequence-length": null, "sequence-id-range": null, "string-length": null, "string-data": null, "measurement-mode": "count_windows", "measurement-request-count": null, "streaming": null, "grpc-compression-algorithm": null, "triton-server-directory": null, "model-repository": null, "ssl-grpc-use-ssl": null, "ssl-grpc-root-certifications-file": null, "ssl-grpc-private-key-file": null, "ssl-grpc-certificate-chain-file": null, "ssl-https-verify-peer": null, "ssl-https-verify-host": null, "ssl-https-ca-certificates-file": null, "ssl-https-client-certificate-type": null, "ssl-https-client-certificate-file": null, "ssl-https-private-key-type": null, "ssl-https-private-key-file": null, "collect-metrics": "True", "metrics-url": "http://localhost:8002/metrics", "metrics-interval": 1000.0}, "_options": {"-m": "add_sub_config_0", "-x": null, "-b": 1, "-u": "localhost:8001", "-i": "grpc", "-f": "add_sub_config_0-results.csv", "-H": null}, "_verbose": {"-v": null, "-v -v": null, "--verbose-csv": "--verbose-csv"}, "_input_to_options": {"model-name": "-m", "model-version": "-x", "batch-size": "-b", "url": "-u", "protocol": "-i", "latency-report-file": "-f", "http-header": "-H"}, "_input_to_verbose": {"verbose": "-v", "extra-verbose": "-v -v", "verbose-csv": "--verbose-csv"}, "_additive_args": {"input-data": null, "shape": null}}, "_ensemble_subconfigs": []}]}, {"-m add_sub_config_0 -b 1 -i grpc -f add_sub_config_0-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_0", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 3.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.9675, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 3.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.9675, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 3.25, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 55.9675, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_0", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.437, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.51, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.539, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.621, "_timestamp": 0}], ["perf_throughput", {"_value": 2282.1, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.004, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.422, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.038, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.074, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.035, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.047, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.437, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.51, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.539, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.621, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 2282.1, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.004, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.422, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.038, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.074, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.035, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.047, "_timestamp": 0}]}}]}, "-m add_sub_config_0 -b 1 -i grpc -f add_sub_config_0-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_0", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 4.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.0195, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 4.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.0195, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 4.25, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.0195, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_0", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.334, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.398, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.498, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.632, "_timestamp": 0}], ["perf_throughput", {"_value": 5966.26, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.321, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.045, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.035, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.019, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.024, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.334, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.398, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.498, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.632, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 5966.26, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.321, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.045, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.035, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.019, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.024, "_timestamp": 0}]}}]}}], "add_sub_config_1": [{"_triton_env": {}, "_model_run_configs": [{"_model_name": "add_sub", "_model_config": {"name": "add_sub_config_1", "platform": "pytorch_libtorch", "maxBatchSize": 2, "input": [{"name": "INPUT__0", "dataType": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "dataType": "TYPE_FP32", "dims": ["16"], "labelFilename": "output0_labels.txt"}, {"name": "OUTPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "instanceGroup": [{"count": 1, "kind": "KIND_GPU"}], "dynamicBatching": {}, "cpu_only": false}, "_perf_config": {"_args": {"service-kind": null, "model-signature-name": null, "async": null, "sync": null, "measurement-interval": null, "concurrency-range": 1, "request-rate-range": null, "request-distribution": null, "request-intervals": null, "binary-search": null, "num-of-sequences": null, "latency-threshold": null, "max-threads": null, "stability-percentage": null, "max-trials": null, "percentile": null, "input-data": null, "shared-memory": null, "output-shared-memory-size": null, "shape": null, "sequence-length": null, "sequence-id-range": null, "string-length": null, "string-data": null, "measurement-mode": "count_windows", "measurement-request-count": null, "streaming": null, "grpc-compression-algorithm": null, "triton-server-directory": null, "model-repository": null, "ssl-grpc-use-ssl": null, "ssl-grpc-root-certifications-file": null, "ssl-grpc-private-key-file": null, "ssl-grpc-certificate-chain-file": null, "ssl-https-verify-peer": null, "ssl-https-verify-host": null, "ssl-https-ca-certificates-file": null, "ssl-https-client-certificate-type": null, "ssl-https-client-certificate-file": null, "ssl-https-private-key-type": null, "ssl-https-private-key-file": null, "collect-metrics": "True", "metrics-url": "http://localhost:8002/metrics", "metrics-interval": 1000.0}, "_options": {"-m": "add_sub_config_1", "-x": null, "-b": 1, "-u": "localhost:8001", "-i": "grpc", "-f": "add_sub_config_1-results.csv", "-H": null}, "_verbose": {"-v": null, "-v -v": null, "--verbose-csv": "--verbose-csv"}, "_input_to_options": {"model-name": "-m", "model-version": "-x", "batch-size": "-b", "url": "-u", "protocol": "-i", "latency-report-file": "-f", "http-header": "-H"}, "_input_to_verbose": {"verbose": "-v", "extra-verbose": "-v -v", "verbose-csv": "--verbose-csv"}, "_additive_args": {"input-data": null, "shape": null}}, "_ensemble_subconfigs": []}]}, {"-m add_sub_config_1 -b 1 -i grpc -f add_sub_config_1-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_1", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.75, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.961, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.75, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.961, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.75, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 55.961, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_1", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.412, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.474, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.495, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.568, "_timestamp": 0}], ["perf_throughput", {"_value": 2421.98, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.399, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.035, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.069, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.034, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.044, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.412, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.474, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.495, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.568, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 2421.98, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.399, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.035, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.069, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.034, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.044, "_timestamp": 0}]}}]}, "-m add_sub_config_1 -b 1 -i grpc -f add_sub_config_1-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_1", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 4.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.1902, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 4.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.1902, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 4.25, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.1902, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_1", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.321, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.357, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.42, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.579, "_timestamp": 0}], ["perf_throughput", {"_value": 6209.88, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.308, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.044, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.033, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.023, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.321, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.357, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.42, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.579, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 6209.88, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.308, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.044, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.033, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.023, "_timestamp": 0}]}}]}, "-m add_sub_config_1 -b 2 -i grpc -f add_sub_config_1-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_1", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.5, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.2845, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.5, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.2845, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.5, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.2845, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_1", "_model_specific_pa_params": {"batch-size": 2, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.4, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.486, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.528, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.573, "_timestamp": 0}], ["perf_throughput", {"_value": 4989.17, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.387, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.033, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.071, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.032, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.043, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.4, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.486, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.528, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.573, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 4989.17, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.387, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.033, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.071, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.032, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.043, "_timestamp": 0}]}}]}, "-m add_sub_config_1 -b 2 -i grpc -f add_sub_config_1-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_1", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 6.666669999999999, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.4687, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 6.666669999999999, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.4687, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 847.249408, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24548.212736, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 6.666669999999999, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.4687, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_1", "_model_specific_pa_params": {"batch-size": 2, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.331, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.367, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.411, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.592, "_timestamp": 0}], ["perf_throughput", {"_value": 12046.2, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.318, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.041, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.035, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.023, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.331, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.367, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.411, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.592, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 12046.2, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.318, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.041, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.035, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.018, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.023, "_timestamp": 0}]}}]}}], "add_sub_config_2": [{"_triton_env": {}, "_model_run_configs": [{"_model_name": "add_sub", "_model_config": {"name": "add_sub_config_2", "platform": "pytorch_libtorch", "maxBatchSize": 1, "input": [{"name": "INPUT__0", "dataType": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "dataType": "TYPE_FP32", "dims": ["16"], "labelFilename": "output0_labels.txt"}, {"name": "OUTPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "instanceGroup": [{"count": 2, "kind": "KIND_GPU"}], "dynamicBatching": {}, "cpu_only": false}, "_perf_config": {"_args": {"service-kind": null, "model-signature-name": null, "async": null, "sync": null, "measurement-interval": null, "concurrency-range": 1, "request-rate-range": null, "request-distribution": null, "request-intervals": null, "binary-search": null, "num-of-sequences": null, "latency-threshold": null, "max-threads": null, "stability-percentage": null, "max-trials": null, "percentile": null, "input-data": null, "shared-memory": null, "output-shared-memory-size": null, "shape": null, "sequence-length": null, "sequence-id-range": null, "string-length": null, "string-data": null, "measurement-mode": "count_windows", "measurement-request-count": 100, "streaming": null, "grpc-compression-algorithm": null, "triton-server-directory": null, "model-repository": null, "ssl-grpc-use-ssl": null, "ssl-grpc-root-certifications-file": null, "ssl-grpc-private-key-file": null, "ssl-grpc-certificate-chain-file": null, "ssl-https-verify-peer": null, "ssl-https-verify-host": null, "ssl-https-ca-certificates-file": null, "ssl-https-client-certificate-type": null, "ssl-https-client-certificate-file": null, "ssl-https-private-key-type": null, "ssl-https-private-key-file": null, "collect-metrics": "True", "metrics-url": "http://localhost:8002/metrics", "metrics-interval": 1000.0}, "_options": {"-m": "add_sub_config_2", "-x": null, "-b": 1, "-u": "localhost:8001", "-i": "grpc", "-f": "add_sub_config_2-results.csv", "-H": null}, "_verbose": {"-v": null, "-v -v": null, "--verbose-csv": "--verbose-csv"}, "_input_to_options": {"model-name": "-m", "model-version": "-x", "batch-size": "-b", "url": "-u", "protocol": "-i", "latency-report-file": "-f", "http-header": "-H"}, "_input_to_verbose": {"verbose": "-v", "extra-verbose": "-v -v", "verbose-csv": "--verbose-csv"}, "_additive_args": {"input-data": null, "shape": null}}, "_ensemble_subconfigs": []}]}, {"-m add_sub_config_2 -b 1 -i grpc -f add_sub_config_2-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_2", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.33333, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.4313, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.33333, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.4313, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.33333, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.4313, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_2", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.557, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.712, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.746, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.818, "_timestamp": 0}], ["perf_throughput", {"_value": 1791.43, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.544, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.05, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.105, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.055, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.557, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.712, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.746, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.818, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 1791.43, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.003, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.544, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.05, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.105, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.055, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]}}]}, "-m add_sub_config_2 -b 1 -i grpc -f add_sub_config_2-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_2", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.5, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.472, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.5, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.472, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.5, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.472, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_2", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.602, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.697, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.742, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.846, "_timestamp": 0}], ["perf_throughput", {"_value": 3314.69, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.005, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.584, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.043, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.111, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.054, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.602, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.697, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.742, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.846, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 3314.69, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.005, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.584, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.043, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.111, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.054, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]}}]}}], "add_sub_config_3": [{"_triton_env": {}, "_model_run_configs": [{"_model_name": "add_sub", "_model_config": {"name": "add_sub_config_3", "platform": "pytorch_libtorch", "maxBatchSize": 2, "input": [{"name": "INPUT__0", "dataType": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "dataType": "TYPE_FP32", "dims": ["16"], "labelFilename": "output0_labels.txt"}, {"name": "OUTPUT__1", "dataType": "TYPE_FP32", "dims": ["16"]}], "instanceGroup": [{"count": 2, "kind": "KIND_GPU"}], "dynamicBatching": {}, "cpu_only": false}, "_perf_config": {"_args": {"service-kind": null, "model-signature-name": null, "async": null, "sync": null, "measurement-interval": null, "concurrency-range": 1, "request-rate-range": null, "request-distribution": null, "request-intervals": null, "binary-search": null, "num-of-sequences": null, "latency-threshold": null, "max-threads": null, "stability-percentage": null, "max-trials": null, "percentile": null, "input-data": null, "shared-memory": null, "output-shared-memory-size": null, "shape": null, "sequence-length": null, "sequence-id-range": null, "string-length": null, "string-data": null, "measurement-mode": "count_windows", "measurement-request-count": null, "streaming": null, "grpc-compression-algorithm": null, "triton-server-directory": null, "model-repository": null, "ssl-grpc-use-ssl": null, "ssl-grpc-root-certifications-file": null, "ssl-grpc-private-key-file": null, "ssl-grpc-certificate-chain-file": null, "ssl-https-verify-peer": null, "ssl-https-verify-host": null, "ssl-https-ca-certificates-file": null, "ssl-https-client-certificate-type": null, "ssl-https-client-certificate-file": null, "ssl-https-private-key-type": null, "ssl-https-private-key-file": null, "collect-metrics": "True", "metrics-url": "http://localhost:8002/metrics", "metrics-interval": 1000.0}, "_options": {"-m": "add_sub_config_3", "-x": null, "-b": 1, "-u": "localhost:8001", "-i": "grpc", "-f": "add_sub_config_3-results.csv", "-H": null}, "_verbose": {"-v": null, "-v -v": null, "--verbose-csv": "--verbose-csv"}, "_input_to_options": {"model-name": "-m", "model-version": "-x", "batch-size": "-b", "url": "-u", "protocol": "-i", "latency-report-file": "-f", "http-header": "-H"}, "_input_to_verbose": {"verbose": "-v", "extra-verbose": "-v -v", "verbose-csv": "--verbose-csv"}, "_additive_args": {"input-data": null, "shape": null}}, "_ensemble_subconfigs": []}]}, {"-m add_sub_config_3 -b 1 -i grpc -f add_sub_config_3-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_3", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.66667, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.4323, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.66667, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.4323, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.66667, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.4323, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_3", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.473, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.583, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.626, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.763, "_timestamp": 0}], ["perf_throughput", {"_value": 2108.93, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.004, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.458, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.04, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.081, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.041, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.052, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.473, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.583, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.626, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.763, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 2108.93, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.004, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.458, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.04, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.081, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.041, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.052, "_timestamp": 0}]}}]}, "-m add_sub_config_3 -b 1 -i grpc -f add_sub_config_3-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_3", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 4.33333, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.561, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 4.33333, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.561, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 4.33333, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.561, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_3", "_model_specific_pa_params": {"batch-size": 1, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.586, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.712, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.758, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.871, "_timestamp": 0}], ["perf_throughput", {"_value": 3402.77, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.005, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.568, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.041, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.105, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.054, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.586, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.712, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.758, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.871, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 3402.77, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.005, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.568, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.041, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.105, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.054, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]}}]}, "-m add_sub_config_3 -b 2 -i grpc -f add_sub_config_3-results.csv --verbose-csv --concurrency-range=1 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_3", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.66667, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.5343, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.66667, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.5343, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.66667, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.5343, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_3", "_model_specific_pa_params": {"batch-size": 2, "concurrency-range": 1}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.558, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.695, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.757, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.845, "_timestamp": 0}], ["perf_throughput", {"_value": 3575.86, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.004, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.543, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.049, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.111, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.056, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.558, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.695, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.757, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.845, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 3575.86, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.004, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.543, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.049, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.111, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.056, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]}}]}, "-m add_sub_config_3 -b 2 -i grpc -f add_sub_config_3-results.csv --verbose-csv --concurrency-range=2 --measurement-mode=count_windows --collect-metrics --metrics-url=http://localhost:8002/metrics --metrics-interval=1000.0": {"_model_variants_name": "add_sub_config_3", "_gpu_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 2.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.5485, "_timestamp": 0, "_device_uuid": null}]]}, "_avg_gpu_data": [["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], ["gpu_utilization", {"_value": 2.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 56.5485, "_timestamp": 0, "_device_uuid": null}]], "_avg_gpu_data_from_tag": {"gpu_used_memory": ["gpu_used_memory", {"_value": 849.34656, "_timestamp": 0, "_device_uuid": null}], "gpu_free_memory": ["gpu_free_memory", {"_value": 24546.115584, "_timestamp": 0, "_device_uuid": null}], "gpu_utilization": ["gpu_utilization", {"_value": 2.25, "_timestamp": 0, "_device_uuid": null}], "gpu_power_usage": ["gpu_power_usage", {"_value": 56.5485, "_timestamp": 0, "_device_uuid": null}]}, "_model_config_measurements": [{"_model_config_name": "add_sub_config_3", "_model_specific_pa_params": {"batch-size": 2, "concurrency-range": 2}, "_non_gpu_data": [["perf_latency_avg", {"_value": 0.601, "_timestamp": 0}], ["perf_latency_p90", {"_value": 0.708, "_timestamp": 0}], ["perf_latency_p95", {"_value": 0.748, "_timestamp": 0}], ["perf_latency_p99", {"_value": 0.839, "_timestamp": 0}], ["perf_throughput", {"_value": 6643.47, "_timestamp": 0}], ["perf_client_send_recv", {"_value": 0.005, "_timestamp": 0}], ["perf_client_response_wait", {"_value": 0.582, "_timestamp": 0}], ["perf_server_queue", {"_value": 0.042, "_timestamp": 0}], ["perf_server_compute_infer", {"_value": 0.114, "_timestamp": 0}], ["perf_server_compute_input", {"_value": 0.054, "_timestamp": 0}], ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]], "_non_gpu_data_from_tag": {"perf_latency_avg": ["perf_latency_avg", {"_value": 0.601, "_timestamp": 0}], "perf_latency_p90": ["perf_latency_p90", {"_value": 0.708, "_timestamp": 0}], "perf_latency_p95": ["perf_latency_p95", {"_value": 0.748, "_timestamp": 0}], "perf_latency_p99": ["perf_latency_p99", {"_value": 0.839, "_timestamp": 0}], "perf_throughput": ["perf_throughput", {"_value": 6643.47, "_timestamp": 0}], "perf_client_send_recv": ["perf_client_send_recv", {"_value": 0.005, "_timestamp": 0}], "perf_client_response_wait": ["perf_client_response_wait", {"_value": 0.582, "_timestamp": 0}], "perf_server_queue": ["perf_server_queue", {"_value": 0.042, "_timestamp": 0}], "perf_server_compute_infer": ["perf_server_compute_infer", {"_value": 0.114, "_timestamp": 0}], "perf_server_compute_input": ["perf_server_compute_input", {"_value": 0.054, "_timestamp": 0}], "perf_server_compute_output": ["perf_server_compute_output", {"_value": 0.067, "_timestamp": 0}]}}]}}]}}}, "ResultManager.server_only_data": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": [["gpu_used_memory", {"_value": 457.0, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_free_memory", {"_value": 24938.0, "_timestamp": 0, "_device_uuid": "GPU-8557549f-9c89-4384-8bd6-1fd823c342e0"}], ["gpu_utilization", {"_value": 0.25, "_timestamp": 0, "_device_uuid": null}], ["gpu_power_usage", {"_value": 55.6305, "_timestamp": 0, "_device_uuid": null}]]}, "MetricsManager.gpus": {"GPU-8557549f-9c89-4384-8bd6-1fd823c342e0": {"name": "NVIDIA TITAN RTX", "total_memory": 25395462144}}, "ModelManager.model_variant_name_manager": {"_model_config_dicts": {"add_sub_config_0": {"name": "add_sub", "platform": "pytorch_libtorch", "max_batch_size": 1, "input": [{"name": "INPUT__0", "data_type": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "data_type": "TYPE_FP32", "dims": ["16"], "label_filename": "output0_labels.txt"}, {"name": "OUTPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "instance_group": [{"count": 1, "kind": "KIND_GPU"}], "dynamic_batching": {}}, "add_sub_config_1": {"name": "add_sub", "platform": "pytorch_libtorch", "max_batch_size": 2, "input": [{"name": "INPUT__0", "data_type": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "data_type": "TYPE_FP32", "dims": ["16"], "label_filename": "output0_labels.txt"}, {"name": "OUTPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "instance_group": [{"count": 1, "kind": "KIND_GPU"}], "dynamic_batching": {}}, "add_sub_config_2": {"name": "add_sub", "platform": "pytorch_libtorch", "max_batch_size": 1, "input": [{"name": "INPUT__0", "data_type": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "data_type": "TYPE_FP32", "dims": ["16"], "label_filename": "output0_labels.txt"}, {"name": "OUTPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "instance_group": [{"count": 2, "kind": "KIND_GPU"}], "dynamic_batching": {}}, "add_sub_config_3": {"name": "add_sub", "platform": "pytorch_libtorch", "max_batch_size": 2, "input": [{"name": "INPUT__0", "data_type": "TYPE_FP32", "dims": ["16"]}, {"name": "INPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "output": [{"name": "OUTPUT__0", "data_type": "TYPE_FP32", "dims": ["16"], "label_filename": "output0_labels.txt"}, {"name": "OUTPUT__1", "data_type": "TYPE_FP32", "dims": ["16"]}], "instance_group": [{"count": 2, "kind": "KIND_GPU"}], "dynamic_batching": {}}}, "_model_name_index": {"add_sub": 3}}}