# Copyright 2020, NVIDIA CORPORATION.
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Values for Model Analyzer
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# The mandatory fields to update are modelPath, resultsPath, and modelName

# Job timeout value specified in seconds
jobTimeout: 900

## Configurations for mounting volumes

# Local path to model directory
modelPath: /home/model

# Local path to export data
resultsPath: /home/results

## Arguments

#Specifies how long to gather server-only metrics
baseDuration: 6

#Specifies list of model batch sizes 
batch: 1,2

#Specifies comma-delimited list of concurrency values
concurrency: 1,2

#Specifies frequency of metric gathering in milliseconds
frequencyMs: 100

#Specifies the max duration of any retry attempt in seconds
maxRetry: 15

#Specifies the model name
#This should match the name Triton is expecting, based on the model's configuration file.
modelName: classification_chestxray_v1

#Specifies the number of seconds perf client runs model before gathering metrics (default: 3)
perfBuffer: 3

## Images
images:

  analyzer:
    image: model-analyzer

  triton:
    image: nvcr.io/nvidia/tensorrtserver
    tag: 20.02-py3