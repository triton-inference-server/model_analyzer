# Copyright 2020, NVIDIA CORPORATION.
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-model-analyzer
  labels:
    app: {{ .Release.Name }}-model-analyzer
    chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
    release: {{ .Release.Name }}
spec:
  backoffLimit: 4
  activeDeadlineSeconds: {{ .Values.jobTimeout }}
  template:
    spec:
      shareProcessNamespace: true
      containers:
      - name: analyzer
        image: {{ .Values.images.analyzer.image }}
        imagePullPolicy: IfNotPresent
        securityContext:
            privileged: true
        args: [
          "kubernetes",
          "--base-duration", "{{ .Values.baseDuration }}",
          "--batch", "{{ .Values.batch }}",
          "--concurrency", "{{ .Values.concurrency }}",
          "--export-path", "/results/",
          "--filename-model", "{{ .Release.Name }}-metrics-model.csv",
          "--filename-server-only", "{{ .Release.Name }}-metrics-server-only.csv",
          "--frequency-ms", "{{ .Values.frequencyMs }}",
          "--max-retry", "{{ .Values.maxRetry }}",
          "--model-names", "{{ .Values.modelName }}",
          "--perf-buffer", "{{ .Values.perfBuffer }}",
          "--triton-version", "{{ .Values.images.triton.tag }}",
          "--export"]
        volumeMounts:
            - name: results
              mountPath: /results
      - name: triton
        image: {{ .Values.images.triton.image }}:{{ .Values.images.triton.tag }}
        imagePullPolicy: IfNotPresent
        volumeMounts:
            - name: model
              mountPath: /model
        args: ["./bin/trtserver", "--model-repository=/model", "--model-control-mode=explicit"]
        resources:
            limits:
                nvidia.com/gpu: 1
      restartPolicy: OnFailure
      volumes:
      - name: results
        hostPath:
            path:  {{ .Values.resultsPath }}
      - name: model
        hostPath:
            path:  {{ .Values.modelPath }}